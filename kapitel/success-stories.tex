\section{Success Stories}
\label{sec:success-stories}

Im Folgenden sollen einige Firmen kurz vorgestellt werden, welche Continuous
Deployment nicht nur aktiv sondern auch erfolgreich einsetzen. Dabei werden
ebenfalls die entwickelten Produkte kurz vorgestellt und besonderes Augenmerk
auf angewandte Methoden und Workflows gerichtet. Sofern Informationen darüber
vorhanden sind welche unterstützenden Technologien verwendet wurden, werden
diese ebenfalls erwähnt.


\subsection{IMVU}
\label{subsec:imvu}
%http://timothyfitz.wordpress.com/2009/02/10/continuous-deployment-at-imvu-doing-the-impossible-fifty-times-a-day/
%http://radar.oreilly.com/2009/03/continuous-deployment-5-eas.html
%http://www.infoq.com/news/2009/03/Continuous-Deployment
%http://www.developsense.com/blog/2009/03/50-deployments-day-and-perpetual-beta/#268747558129898245
%http://www.slideshare.net/bgdurrett/sds-2010-continuous-deployment-at-imvu

Als erstes Beispiel dient IMVU\footnote{IMVU: \url{http://www.imvu.com/}},
eine soziale Online Community, in der in einer virtuellen Realität mit Hilfe
von 3D Avataren kommuniziert, Spiele gespielt und eigene Inhalte erschaffen
und ausgetauscht werden können.

IMVU war eines der ersten \emph{Lean Startup} Unternehmen welche Continuous
Deployment aktiv einsetzten. Dabei ist dies aber nicht vorab im Ganzen geplant
worden, sondern inkrementell entstanden \cite{Fitz2009-02-10}. Derzeit sind
bei IMVU zirka 50 technische Mitarbeiter angestellt \cite{imvu10}. Ein
wichtiger Punkt warum bei, vor allem so vielen Entwicklern, Continuous
Deployment funktioniert, ist, dass es ein zentraler Bestandteil der
Firmenkultur ist. \\
Als Vorteile von Continuous Deployment werden von IMVU die folgenden Punkte
genannt \cite{imvu10}:

\begin{itemize*}
    \item Regression wird sehr rasch erkannt
    \item Fehler können schneller behoben werden, da zwischen dem einspielen
          eines Fehlers und der Meldung über ein Problem nicht viel Zeit vergeht
    \item Der Release einer neuen Version erzeugt keinen zusätzlichen Overhead
    \item Als Feedback bekommen sie sofort messbare Kerndaten von echten Kunden
\end{itemize*}

\minisec{Workflow} Eine wichtige Grundvoraussetzung für Continuous Deployment
bei IMVU ist wie schon in Abschnitt~\ref{minisec:continuous-integration} auf
Seite~\pageref{minisec:continuous-integration} gezeigt: Continuous
Integration. Als Technologie kommt hier Buildbot\footnote{Buildbot:
\url{http://trac.buildbot.net/}} zum Einsatz \cite{imvu09}. Um die Vorteile
von Continuous Integration voll ausnützen zu können wird beim Entwickeln
selbst \emph{Commit Early Commit Often} praktiziert \cite{Fitz2009-02-10}. Ist
ein Feature fertig entwickelt, oder ein Bug behoben worden, werden zuerst
lokale Tests auf der Entwicklermaschine durchgeführt. Wenn all diese Tests
positiv durchlaufen wurden, wird der neue Code in die Versionsverwaltung
eingespielt \cite{imvu10}.

Erst jetzt werden sämtliche Tests der Test-Suite angestoßen. Zurzeit sind dies
zirka $15.000$ Tests aus den Bereichen Unit-, Funktions- und Verhaltenstests
\cite{imvu10}. Dabei werden die folgenden Technologien eingesetzt:

\begin{itemize*}
    \item Selenium Core wird mit einem eigens entwickelten API Wrapper für
          die Verhaltens-Tests eingesetzt
    \item YUI Test wird für Browser basierte JavaScript Unit-Tests verwendet
    \item PHP SimpleTest
    \item Erlang EUnit
    \item Python UnitTests
\end{itemize*}

Schlägt nur einer der Tests fehl wird der zuletzt eingespielte Code
zurückgesetzt. Es ist zu beachten, dass nicht nur die Masse an Tests, sprich
die Testabdeckung, wichtig für IMVU ist, sondern auch die Qualität der Tests.
Ein weiteres Merkmal ihrer Firmenkultur ist nämlich das Schreiben von
qualitativ hochwertigen Tests \cite{Fitz2009-02-10}. Durch diese Maßnahmen,
also dem Schreiben von gründlichen hochwertigen Tests, welche sich auf alle
Aufgabenbereiche verteilen, schafft es IMVU ein separates
Qualitätssicherungsteam überflüssig zu machen.

Nachdem sämtliche Tests erfolgreich durchgeführt wurden, wird ein eigen
entwickeltes Build-Skript angestoßen um den neuen Code in die
Produktionsumgebung einzuspielen. IMVUs Produktionsumgebung besteht aus einem
Cluster mit derzeit zirka 700 Servern \cite{imvu10}. Das Build-Skript verteilt
zwar den Code im gesamten Cluster, umgestellt werden zunächst aber nur eine
gewisse Prozent Anzahl an Servern. Die Umstellung auf den neuen Code erfolgt
recht simpel per Symlink.

Durch ein ständig aktives Monitoring werden fortlaufend Messwerte über den
Gesundheitszustand des Clusters gesammelt. Siehe dazu auch
Abschnitt~\ref{minisec:immunization} auf Seite~\pageref{minisec:immunization}.
Diese Messdaten beinhalten Werte für CPU-, Speicher- und Netzwerklast, aber
auch Business Metriken kommen zum Einsatz \cite{Fitz2009-02-10},
\cite{imvu09}. Findet nach einer gewissen Zeitspanne keine Regression des
Clusters statt wird der neue Code auf allen Servern aktiv geschalten. Durch
das begleitende Monitoring könnte so noch immer jederzeit auf die vorherige
Version zurückgewechselt werden.

Kurz sei noch erwähnt wie bei IMVU mit den relationalen Datenbanken verfahren
wird. Da ein Datenbank Schema Rollback nur schwer möglich ist, bzw. das
Verändern des Schemas einen schwerwiegenden Eingriff darstellt, durchlaufen
Schemamodifikationen, im Gegensatz zum Code Deployment, einen formalen Review
Prozess. Müssen tatsächlich die Strukturen der Tabellen angepasst werden,
bleiben die alten Tabellen weiterhin bestehen und es werden einfach neue
Tabellen mit der neuen Struktur erstellt. Die Daten werden dann per \emph{Copy
on Read} bzw. per Hintergrund-Job migriert \cite{imvu10}.

IMVU schafft nach dieser Methode derzeit zirka 50 Deployments pro Tag, was
mitunter auch an der geringen Durchlaufzeit der Test Suite liegt -- diese
liegt unter 10 Minuten \cite{Fitz2009-02-10}. Auf einen wichtigen
Vorteil für IMVU bezüglich Continuous Deployment zurückkommend fasst dies
Timothy Fitz wie folgt zusammen:

\begin{quote}
\zitat{This is a software release process implementation of the classic Fail
Fast pattern. The closer a failure is to the point where it was introduced,
the more data you have to correct for that failure.}~\cite{Fitz2009-02-08}
\end{quote}


\subsection{Huitale}
%http://books.google.co.uk/books?id=G3zTzENmyFIC&lpg=PA111&ots=CuQj-1x2oU&lr&pg=PA111#v=onepage&q&f=false
%http://huitale.blogspot.com/2011/03/presentation-continuous-deployment.html

Huitale ist ein finnisches \emph{Lean Startup} Unternehmen aus Helsinki
welches Dienstleistungen im agilen Umfeld für Training und Consulting, aber
auch Softwareentwicklung, anbietet. Sie können sich dabei auf ihr eigen
entwickeltes Produkt \emph{nextdoor.fi}\footnote{nextdoor.fi:
\url{http://http://www.nextdoor.fi}} berufen. Nextdoor.fi ist eine online
Plattform um Dienstleistungen im Haushaltsservicebereich anzubieten und
einzukaufen. Die Plattform hat derzeit zirka $2.000$ aktive Benutzer und im
Monat ungefähr $30.000$ Besucher \cite{Taipale2010}.

Huitale hat während der Entwicklung von \emph{nextdoor.fi} einen angepassten
Lean Software Entwicklungsprozess umgesetzt, welcher im Folgenden kurz
vorgestellt wird.

\minisec{Workflow} Der Softwareentwicklungsprozess von Huitale setzt viele
Elemente von \emph{Kanban} ein um ihren Prozess zu visualisieren und mess- und
steuerbar zu machen. Näheres zu Kanban siehe Abschnitt~\ref{subsec:monat-auf-woche}
auf Seite~\pageref{subsec:monat-auf-woche}. 

Als Basis für neue Funktionalität dienen \emph{Minimum Marketable Features}.
Ein \emph{Minimum Marketable Feature} ist im Gegensatz zu einem normalen
Feature ein minimales Set an Funktionalität welches dem Kunden einen Mehrwert
bietet. Dieser Mehrwert muss nicht unbedingt als reiner Gewinn gemessen
werden, damit könnten zum Beispiel auch Kostenersparnisse oder erhöhte
Kundenzufriedenheit gemeint sein \cite{denne2003software}.

Sämtliche ermittelten \emph{MMFs} landen nach Priorität sortiert in einer
\emph{Product Queue}. Diese Queue hat ein \emph{Work in
Progress} Limit von sieben. Befinden sich nur noch zwei \emph{MMFs} in der Queue
können neue aufgenommen werden. Diese Queue orientiert sich also stark an
dem Puffer Konzept aus Kanban. Die Entwicklungsabteilung selbst hat ein
\emph{Work in Progress} Limit von zwei \cite{Taipale2010}.

Ein \emph{MMF} wird dann als fertig entwickelt angesehen, wenn es dafür eine
ausreichende Anzahl qualitativ hochwertiger Unit- und Akzeptanztests gibt und
diese in der Continuous Integration Umgebung fehlerfrei ausgeführt wurden.
Weiters findet eine automatisierte Qualitätssicherung mittels statischer
Codeanalyse (Checkstyle\footnote{Checkstyle:
\url{http://checkstyle.sourceforge.net/}} und PMD\footnote{PMD:
\url{http://pmd.sourceforge.net/}}) statt \cite{Taipale2010}. Der letzte
verpflichtende Schritt besteht aus einem \emph{Peer Review}. Werden all diese
Schritte erfolgreich durchlaufen gilt ein \emph{MMF} als \emph{done} und wird
in 24h Zyklen deployed.\\
Das Continuous Deployment Konzept selbst ist sehr stark an das von IMVU
angelehnt (siehe Abschnitt~\ref{subsec:imvu}). Auch hier gibt es ein 24/7
Monitoring des Produktivsystems mit der Möglichkeit, die täglich
stattfindenden Backups, jederzeit automatisiert wiedereinzuspielen (Immune
System mit automatischen Rollbacks \ref{minisec:immunization}).

Die Organisation des Teams war ursprünglich stark an SCRUM mit einem
\emph{Single Product Owner} angelehnt. Dies wurde aber zu Gunsten einer Zwei-
Team-Strategie aufgegeben. Jetzt gibt es ein \emph{Problem Team} und ein
\emph{Solution Team}. Dem \emph{Problem Team} steht der CEO vor und besteht
weiters aus dem CTO, Marketing \& Sales und User Experience Experten. Der CTO
steht zusätzlich dem \emph{Solution Team} vor, welches auch die Entwickler
beinhaltet \cite{Taipale2010}.\\ Eigene Teams für das Testen oder den
laufenden Betrieb gibt es nicht. Diese Aufgaben werden vom \emph{Solution
Team} mit übernommen. Bemerkenswert ist auch dass es bei Huitale keine
Vollzeit angestellten Entwickler gibt \cite{huitale11}.

Die Ergebnisse dieses Vorgehens sprechen für sich. Die \emph{lead
time}\footnote{lead time: Die Zeit vom Erfassen eines Features bis zur
Fertigstellung} neuer Features kann Aufgrund der ständig gemessenen und
ausgewerteten Daten sehr genau angegeben werden. Im Durchschnitt beträgt diese
derzeit 8 Tage, bei kleineren Features zirka 3 Tage. Das Entwickeln einer
ersten \emph{Public Beta} dauerte mit dieser Methode nur 120 Manntage
\cite{Taipale2010}.

Durch das Monitoring werden auftretende Bugs sehr rasch erkannt und können in
der Regel innerhalb einer Stunde korrigiert werden. Möglich wurde all dies
durch disziplinierte und erfahrene Mitarbeiter. Sämtliche Entwickler hatten
bereits Erfahrung mit agilen Entwicklungsmethoden. Auch Kanban wird als
wichtige Stütze im Finden von Verbesserungspotenzial des Prozesses angegeben.
In vier Jahren gab es bei täglichen Deployments insgesamt nur zwei schwerere
Bugs \cite{Taipale2010}.


\subsection{Digg}
%http://about.digg.com/blog/continuous-deployment-code-review-and-pre-tested-commits-digg4

Digg\footnote{Digg: \url{http://www.digg.com}} ist eine \emph{Social News}
Online-Plattform, dessen Grundfunktionalität das Bewerten von Artikeln durch
die Benutzer ist. Dabei können die Artikel entweder positiv (\emph{digging})
oder negativ (\emph{burrying}) bewertet werden. Am 25.~August 2010 wurde
offiziell die Version 4 der Website frei gegeben \cite{digg4-launch}, was zu
reger Kritik seitens der Benutzer geführt hat, da die Website zu Beginn des
Upgrades teilweise unerreichbar, bzw. instabil war. Weiters wurde durch das
Upgrade ein neues Design eingeführt und bekannte Funktionen herausgenommen
\cite{digg4-critics}.

Aus Entwicklersicht ist das Upgrade auf Version 4 insofern interessant, da mit
dieser Version auch ein Continuous Deployment Prozess realisiert wurde
\cite{digg4}. Seit August 2010 gibt es daher bei Digg keine geplanten Releases
mehr. Alle Änderungen, also Bug-Fixes und neue Features, gehen sofort live.
Auch bei Digg wird dabei auf manuelles Testen der Änderungen verzichtet.

Als große Herausforderung wird der Balanceakt zwischen der Agilität und
Geschwindigkeit von Continuous Deployment und den Anforderungen an Stabilität
und Verlässlichkeit genannt. Dessen ungeachtet gelten die geringe
Durchlaufzeit und das unmittelbare Feedback bezüglich Änderungen bei Digg als
immens wertvoll \cite{digg4}.

\minisec{Workflow} Bei Digg wurde schon, bevor Continuous Deployment
eingeführt wurde, ein Ökosystem aus Entwicklungstools und Techniken eingesetzt
welche den Schritt zu Continuous Deployment erheblich erleichterten. Als
Versionierungssystem wurde Git verwendet, die UI-Tests verwendeten Selenium
und wurden per Continuous Integration mittels Hudson ausgeführt. Hudson wurde
weiters für das Build-Management verwendet. Das Management und Monitoring der
Infrastruktur wurde mittles \emph{puppet} umgesetzt.

Als wichtigste Ergänzung dieses Ökosystems wird Gerrit\footnote{Gerrit:
\url{http://code.google.com/p/gerrit/}} genannt \cite{digg4}. Gerrit ist ein
Code Review System für Git basierte Softwareprojekte. Dabei werden Änderungen,
so genannte \emph{Patchsets}, nach einem Commit nicht sofort in den Master
Branch der Versionsverwaltung eingespielt, sondern von Gerrit zum Review
freigegeben. Erst nachdem diese Änderungen auch von anderen Entwicklern
abgesegnet wurden, kann der neue Code in den Master Branch eingespielt werden.

Gerrit bietet zusätzlich für jedes \emph{Patchset} auch ein \emph{Verified
Flag}. Über dieses Flag lässt sich Gerrit sehr gut mit Continuous Integration
Systemen wie Hudson verbinden, indem das Flag entsprechend dem Ausgang von
automatisierten Tests gesetzt wird. Digg verwendet für die Integration von
Gerrit und Hudson das \emph{Gerrit Trigger} Plugin für Hudson.

Der generelle Ablauf bei Digg ist jetzt wie folgt: Nachdem ein neues
\emph{Patchset} eingespielt wurde, wird dies zum Review freigegeben.
Zusätzlich werden zunächst ein Subset an Unit- und UI-Tests ausgeführt
(Vortests). Der Grund warum nicht gleich sämtliche Tests ausgeführt werden ist
die Dauer die die komplette Testsuite zum Durchlauf benötigen würde. Falls die
Änderungen durch das Review freigegeben und die Tests fehlerfrei durchlaufen
wurden, findet ein Merge to Master statt, die Änderungen landen also im
Hauptzweig der Versionsverwaltung. Erst jetzt werden sämtliche Unit-Tests
ausgeführt und anschließend der neue Build in eine interne Staging Umgebung
eingespielt. Von dort wird, nach erfolgreichem Absolvieren sämtlicher UI-
Tests, in die Produktionsumgebung deployed.

Andrew Bayer, einem Entwickler bei Digg zufolge \cite{digg4}, ist dieser
Prozess bei weitem nicht perfekt, so muss immer noch recht oft manuell
eingegriffen werden nachdem ein Build bei den Vortests nicht durchgekommen
ist. Als Grund wird hier die Instabilität einiger Tests genannt. Dennoch
werden das Review-System und die Möglichkeit rasch Bug-Fixes einzuspielen
positiv hervorgehoben.


\subsection{Flickr}
%http://sna-projects.com/blog/2011/06/continuous-deployment-flickr/
%http://code.flickr.com/blog/2009/12/02/flipping-out/
%http://www.slideshare.net/jallspaw/10-deploys-per-day-dev-and-ops-cooperation-at-flickr

Flickr\footnote{Flickr: \url{http://www.flickr.com}} ist eine
Hosting-Plattform für Fotos und Videos. Dabei können Fotos und Videos
hochgeladen, verwaltet und für andere zum Austausch freigegeben werden. Flickr
bietet zusätzlich eine über Webservices realisierte API an. Die Firma wurde
2005 von \emph{Yahoo!} übernommen und beschäftigte Mitte 2011 zirka 25
Angestellte \cite{flickr11}.

Flickr setzt bei der Weiterentwicklung und Wartung ihrer Plattform einen über
die Zeit inkrementell entstandenen Continuous Deployment Przess ein.
Interessant an diesem Prozess ist das hohe Maß an Veranwortung welches jedem
einzelnen Enwickler selbst zugetraut wird, denn jeder Entwickler ist bei
Flickr gleichzeitig auch Release Manager. Über ein webbasiertes Deployment-Tool
ist es allen Entwicklern möglich das Deployment eines neuen Builds zu
starten. Über dieses Tool wird derzeit in der Regel 10 mal am Tag eine neue
Version deployed. Es gibt aber auch Tage an denen keine neue Version deployed
wird. Das Maximum wären zirka 50 Deployments am Tag \cite{flickr11}.

Möglich wird dies durch eine Firmenphilosophie die eine professionelle
Einstellung zur Softwareentwicklung fördert \cite{flickr11}. Da aber Menschen
auch Fehler machen gibt es zusätzliche Maßnahmen um dem entgegenzuwirken. Wie
schon in Abschnitt~\ref{minisec:immunization} auf
Seite~\pageref{minisec:immunization} vorgestellt, spielt Immunization dabei
eine wichtige Rolle. Daher wird beim Planen von neuen Features zum Beispiel
schon eng mit dem Operations-Team zusammengearbeitet um die richtigen Metriken
auszuwählen, die den ordnungsgemäßen Betrieb des Features sicherstellen
können. Weiters gibt es die Möglichkeit das letzte Deployment per \emph{1
Klick} Lösung wieder rückgängig zu machen.

\minisec{Workflow} Bei der Entwicklung selbst werden keine \emph{Branches} in
der Versionsverwaltung (Flickr verwendet Subversion) angelegt. Das heißt
alles, auch neue Features, landen sofort im Hauptzweig (HEAD). Dies ist für
ein schnelles Bugfixing zwar von Vorteil, bei neuen Features, deren
Entwicklung teilweise Monate in Anspruch nehmen, stellt dies jedoch ein
Problem dar. Fertig entwickelte Features die noch nicht zum Release
freigegeben sind würden so einfach angezeigt werden. Schlimmer noch wären
halbfertige, die Website möglicherweise in negativer Art beeinträchtigende
Features die bereits einer breiten Öffentlichkeit zugänglich sind. Als Lösung
kommen hier die in Abschnitt~\ref{minisec:featureflags} auf
Seite~\pageref{minisec:featureflags} vorgestellten Feature Flags zum Einsatz
\cite{flickr09}.

Weiters werden bei Flickr Feature Flags eingesetzt um Code gezielt für
verschiedene Umgebungen (Entwicklung, Staging oder Produktion) freizuschalten.
Die Einstellungen welche Features aktiviert sind und welche nicht werden dabei
recht einfach über Konfigurationsdateien realisiert. Der Vorteil daran ist,
dass sobald ein Feature fertig entwickelt wurde, die Aktivierung auf
sämtlichen Servern durch eine einzige Zeile in einer Konfigurationsdatei
möglich ist. Die Steuerung der Features ist aber nicht auf verschiedene
Umgebungen begrenzt, sie können sogar für einzelne Benutzer freigeschalten
werden. Der einzige Nachteil der Feature Flags ist, dass Code teilweise 
doppelt vorhanden ist und nach dem Launch eines neuen Features der alte Code
manuell entfernt werden muss. Dies geschieht in der Regel zirka 3 Monate nach
dem Launch \cite{flickr11}.

Ein anderer interessanter Aspekt wie bei Flickr mit neuen Features umgegangen
wird sind \emph{Dark Launches} \cite{flickr11}. Dabei werden neue Features
komplett vom User Interface bis zur Datenbank ausgeführt, dem Benutzer wird
davon aber nichts angezeigt. So können die Auswirkungen die neue Features auf
das Gesamtsystem haben vorab mit echtem Feedback getestet werden.

Wie schon erwähnt tragen die Entwickler bei Flickr sehr viel Verantwortung.
Dies schlägt sich schon beim Testen nieder. So liegt die Hauptverantwortung
für das Testen bei jedem Entwickler selbst \cite{flickr11}. Es gibt keine
allumfassende Test Suite die automatisiert durch Continuous Integration
sämtliche Bereiche der Anwendung gründlich testet. Ausführliche Unit- und
Loadtests werden von den Entwicklern direkt in der Entwicklungsumgebung
durchgeführt.

Es existiert zwar eine Stagingumgebung die nach jedem Commit aktualisiert
wird, dort werden aber nur noch rudimentäre Tests durchgeführt. So zum
Beispiel ob die verwendeten Datenbankreferenzen auch auf die
Produktionsdatenbanken zeigen und nicht auf die Entwicklungsumgebung. Auch
Performance Tests werden in dieser Stagingumgebung durchgeführt. Als
Continuous Integration Tool kommt hier Hudson zum Einsatz und die
automatisierten Tests benötigen in dieser Umgebung derzeit nur zirka 3
Minuten.

Über das zuvor kurz angesprochene Deployment Tool kann anschließend der in der
Stagingumgebung befindliche Build deployed werden. Dabei werden dem Entwickler
der die neue Version frei gibt noch einmal sämtliche Änderungen am Quellcode
angezeigt, die er oder andere zwischenzeitlich vorgenommen haben. Damit nicht
mehrere Entwickler gleichzeitig ein neues Release freigeben können wird das
Deployment Tool für andere gesperrt sobald ein Entwickler anfängt damit zu
arbeiten.

Auch diesem Prozess wird eingeräumt dass er nicht perfekt sei. So äußerte sich
Ross Harmes darüber folgendermaßen:

\begin{quote}
\zitat{This style of development isn’t all rainbows and sunshine. $(\dots)$
But overall, we find it helps us develop new features faster and with fewer
bugs.}~\cite{flickr09}
\end{quote}

Michael Deerkoski zufolge \cite{flickr11} war es ihnen mit diesem Prozess
möglich, einen Bug innerhalb von 35 Minuten ab der Meldung durch einen
Benutzer zu beheben. \emph{Zu beheben} bedeutet in diesem Zusammenhang
natürlich dass der Bugfix bereits in der Produktionsumgebung eingespielt ist.

%\subsection{WiredReach}
%http://www.justin.tv/startuplessonslearned/b/262656299
%http://www.startuplessonslearned.com/2010/01/case-study-continuous-deployment-makes.html

%\subsection{Wealthfront}
%http://www.justin.tv/startuplessonslearned/b/286511488?utm_campaign=archive_embed_click&utm_source=www-cdn.justin.tv
%http://eng.wealthfront.com/2010/05/deployment-infrastructure-for.html
%http://eng.wealthfront.com/2010/06/applied-lean-startup-ideas-continuous.html
